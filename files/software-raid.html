<!DOCTYPE html>
<html lang="">
<head>
<meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
<title>Software-RAID › ubuntuusers statisches Wiki</title>
<link href="./_/34e5d78db234405457773cc26741aada99f7fff2.css" rel="stylesheet" type="text/css"/>
<link href="./_/61af784fc5c93e296fec3be63b8e0bb48443727c.css" rel="stylesheet" type="text/css"/>
<link href="./_/634e8d1015b02df998cdec7cb07c5aff61d068b5.css" rel="stylesheet" type="text/css"/>
<link href="./_/b583ff7e37147497a59224ccf54cfee812a1d21b.css" rel="stylesheet" type="text/css"/>
<link href="./_/a0d5775ed6f36f8cc5b12bcf2f1c1bd98a3eb225.css" rel="stylesheet" type="text/css"/>
<link href="./_/98de73bded109a634cbd1e924abdd8c8964b8df2.css" media="print" rel="stylesheet" type="text/css"/>

<meta content="#a87300" name="theme-color"/>

</head>
<body>
<div class="wrap">
<div class="header">
<h1><a href="http://ubuntuusers.de/"><span>ubuntuusers.de</span></a></h1>
<ul class="tabbar">
<li class="portal">
<div class="tab_left"></div>
<div class="tab_center"><a href="http://ubuntuusers.de/">Portal<span></span></a></div>
<div class="tab_right"></div>
</li>
<li class="forum">
<div class="tab_left"></div>
<div class="tab_center"><a href="http://forum.ubuntuusers.de/">Forum<span></span></a></div>
<div class="tab_right"></div>
</li>
<li class="wiki active">
<div class="tab_left"></div>
<div class="tab_center"><a href="http://wiki.ubuntuusers.de/">Wiki<span></span></a></div>
<div class="tab_right"></div>
</li>
<li class="ikhaya">
<div class="tab_left"></div>
<div class="tab_center"><a href="http://ikhaya.ubuntuusers.de/">Ikhaya<span></span></a></div>
<div class="tab_right"></div>
</li>
<li class="planet">
<div class="tab_left"></div>
<div class="tab_center"><a href="http://planet.ubuntuusers.de/">Planet<span></span></a></div>
<div class="tab_right"></div>
</li>
<li class="community">
<div class="tab_left"></div>
<div class="tab_center"><a href="http://wiki.ubuntuusers.de/Mitmachen">Mitmachen<span></span></a></div>
<div class="tab_right"></div>
</li>
</ul>
</div>
<div class="body">
<div class="appheader">

<div class="pagetitle">
<h1 class="breadcrumb_title">
<a class="separator" href="./startseite.html">
              Wiki
            </a>
</h1>
<h2 class="breadcrumb_subtitle"><a href="./software-raid.html">Software-RAID</a></h2>
</div>
</div><div class="message staticwikinote"><strong>Hinweis:</strong> Dies ist ein statischer Snapshot unseres Wikis vom Jan. 17, 2018 und kann daher nicht bearbeitet werden. Der aktuelle Artikel ist unter <a href="http://wiki.ubuntuusers.de/Software-RAID">wiki.ubuntuusers.de</a> zu finden.</div>

<!--[if lt IE 8]>
      <div class="message fail">Bitte installiere den Internet Explorer 8 oder neuer.</div>
      <![endif]-->
<div class="page_content">
<div class="navi_sidebar navigation">
<div class="container">
<h3 class="navi_wiki">Wiki</h3>
<ul>
<li><a href="./wiki/index.html">Index</a></li>
<li><a href="./wiki/recentchanges.html">Letzte Änderungen</a></li>
<li><a href="./wiki/neue_artikel.html">Liste neuer Artikel</a></li>
<li><a href="./wiki.html">Übersicht</a></li>
<li><a href="./wiki/faq_-_häufig_gestellte_fragen.html">FAQ</a></li>
<li><a href="./wiki/benutzung.html">Benutzung</a></li>
<li><a href="./kategorien.html">Kategorie</a></li>
<li><a href="./wiki/tagcloud.html">Wortwolke</a></li>
</ul>
<h3 class="navi_join">Mitmachen</h3>
<ul>
<li><a href="./wikiartikel_anlegen.html">Wikiartikel anlegen</a></li>
<li><a href="./howto.html">Howto anlegen</a></li>
<li><a href="./wiki/referenz.html">Wiki-Referenz</a></li>
<li><a href="./wiki/syntax.html">Wiki-Syntax</a></li>
<li><a href="./baustelle.html">Baustellen</a></li>
<li><a href="./wiki/artikelideen.html">Artikelideen</a></li>
<li><a href="./wiki/ungetestet.html">Ungetestete Artikel</a></li>
<li><a href="./wiki/vorlagen/ausbaufähig/a/backlinks.html">Ausbaufähige Artikel</a></li>
<li><a href="./wiki/vorlagen/fehlerhaft/a/backlinks.html">Fehlerhafte Artikel</a></li>
<li><a href="https://forum.ubuntuusers.de/forum/wiki/">Rund ums Wiki</a></li>
</ul>
<h3 class="navi_config">Konfiguration</h3>
<ul>
<li><a href="./software-raid/a/backlinks.html">Backlinks anzeigen</a></li>
<li>
        Exportieren
        <ul>
<li><a href="./software-raid/a/export/meta.html" rel="nofollow">Metadaten</a></li>
<li><a href="./software-raid/a/export/raw.html" rel="nofollow">Rohformat</a></li>
<li><a href="./software-raid/a/export/html.html" rel="nofollow">HTML</a></li>
</ul>
</li>
</ul>
</div>
</div>

<div class="content content_tabbar content_sidebar">
<h1 class="pagetitle"><a href="./software-raid/a/backlinks.html">Software-RAID</a></h1>
<div id="page"><p>
</p><div class="box tested_for"><h3 class="box tested_for">Dieser Artikel wurde für die folgenden
Ubuntu-Versionen getestet:</h3><div class="contents"><p>
</p><ul><li><p><a class="internal" href="./xenial_xerus.html">Ubuntu 16.04</a> Xenial Xerus</p></li><li><p><a class="internal" href="./trusty_tahr.html">Ubuntu 14.04</a> Trusty Tahr</p></li></ul></div></div><p>
</p><p>
</p><div class="box advanced"><h3 class="box advanced">Artikel für fortgeschrittene Anwender</h3><div class="contents"><p>
Dieser Artikel erfordert mehr Erfahrung im Umgang mit
Linux und ist daher nur für fortgeschrittene Benutzer
gedacht.
</p></div></div><div class="box knowledge"><h3 class="box knowledge">Zum Verständnis dieses Artikels sind folgende Seiten hilfreich:</h3><div class="contents"><p>
</p><ol class="arabic"><li><p><a class="crosslink anchor" href="#source-1" id="source-1"></a> <a class="internal" href="./systeminformationen_ermitteln.html#Festplatten">Systeminformationen ermitteln</a></p></li><li><p><a class="crosslink anchor" href="#source-2" id="source-2"></a> <a class="internal" href="./pakete_installieren.html">Installation von Programmen</a></p></li><li><p><a class="crosslink anchor" href="#source-3" id="source-3"></a> <a class="internal" href="./datenträger.html#Wie-heissen-die-Datentraeger">Wie heißen die Datenträger</a></p></li><li><p><a class="crosslink anchor" href="#source-4" id="source-4"></a> <a class="internal" href="./partitionierung.html">Partitionierung</a></p></li><li><p><a class="crosslink anchor" href="#source-5" id="source-5"></a> <a class="internal" href="./terminal.html">Ein Terminal öffnen</a></p></li><li><p><a class="crosslink anchor" href="#source-6" id="source-6"></a> <a class="internal" href="./sudo.html">Root-Rechte erlangen</a></p></li><li><p><a class="crosslink anchor" href="#source-7" id="source-7"></a> <a class="internal" href="./dateisystem.html">Dateisystem</a></p></li><li><p><a class="crosslink anchor" href="#source-8" id="source-8"></a> <a class="internal" href="./mount.html">mount</a></p></li><li><p><a class="crosslink anchor" href="#source-9" id="source-9"></a> <a class="internal" href="./fstab.html">fstab</a></p></li></ol></div></div><p>
</p><div class="toc toc-depth-1"><div class="head">Inhaltsverzeichnis</div><ol class="arabic"><li><a class="crosslink" href="#Grundsaetzliche-Informationen">Grundsätzliche Informationen
</a></li><li><a class="crosslink" href="#Installation">Installation
</a></li><li><a class="crosslink" href="#Anlegen-eines-RAID">Anlegen eines RAID
</a></li><li><a class="crosslink" href="#Wartung">Wartung
</a></li><li><a class="crosslink" href="#Begriffe-und-Details">Begriffe und Details
</a></li><li><a class="crosslink" href="#Problembehebung">Problembehebung
</a></li><li><a class="crosslink" href="#Komplexe-Aufgaben">Komplexe Aufgaben
</a></li><li><a class="crosslink" href="#Links">Links
</a></li></ol></div><p><img alt="Wiki/Icons/hd.png" class="image-left" src="./_/55715cf3ffb7d75ccb763ca79296a2a2b6c15d8f.png"/>
Ein <a class="interwiki interwiki-wikipedia" href="https://de.wikipedia.org/wiki/RAID">RAID</a> (<strong>R</strong>edundant <strong>A</strong>rray of <strong>I</strong>ndependent <strong>D</strong>isks) dient dazu, mehrere physikalische Festplatten zu einem oder mehreren logischen Laufwerken zu vereinen und dadurch einen <strong>schnelleren Datenzugriff</strong> und/oder eine <strong>erhöhte Verfügbarkeit des Systems</strong> im Falle eines Festplattendefektes zu erreichen. Native Hardware-RAID-Controller, die unter Linux unterstützt werden (z.B. von 3Ware, Adaptec, etc.), sind aber für den Heimgebrauch oft zu teuer. Diese braucht man aber nicht zwingend, wenn man unter Linux ein Software-RAID verwendet.</p><p>Als weitere Alternative können die Festplatten auch an sog. FakeRAID-Controllern verwendet werden, z.B. Onboard-RAID-Controller. Allerdings wird von dieser Variante im Allgemeinen abgeraten, da beispielsweise oft Kernelmodule (Treiber) fehlen oder diese nur für bestimmte Kernelversionen zur Verfügung stehen. Dies, als auch der Umstand, dass bei beiden Varianten (Software-Raid und Fake-Raid) die CPU die Hauptarbeit macht zeigt, dass hier ein Software-Raid vorzuziehen ist. Der Einsatz der Fake-Raid Variante würde dann Sinn machen, wenn via <a class="internal" href="./dualboot.html">Dual Boot</a> Linux und Windows auf die gleichen Raid-Partitionen zugreifen sollen.</p><div class="section_1"><h2 id="Grundsaetzliche-Informationen">Grundsätzliche Informationen<a class="headerlink" href="#Grundsaetzliche-Informationen">¶</a></h2><p>
</p><ul><li><p>Im Allgemeinen macht es nur Sinn, Partitionen gleicher Größe zu verwenden, die auf unterschiedlichen Festplatten angelegt sind.</p></li><li><p>Um das komplette System auf einem RAID-Verbund zu installieren, bietet es sich an, das System über die <a class="internal" href="./alternate_installation.html">Alternate-CD</a> aufzusetzen. Die Alternate-CD unterstützt bereits bei der Installation das Erstellen üblicher RAID-Varianten. Dies findet man unter dem Punkt: "Partitionieren". Ab <a class="internal" href="./quantal.html">Ubuntu 12.10</a> ist die Alternate-CD nur noch bei <a class="internal" href="./lubuntu.html">Lubuntu</a> verfügbar. Dann kann man auf die <a class="internal" href="./server_installation.html">Server-CD</a> ausweichen und den gewünschten <a class="internal" href="./desktop.html">Desktop</a> nachträglich installieren.</p></li><li><p>Ubuntu unterstützt von Haus aus die RAID-Varianten 0, 1, 5, 6 und 10. Details zu den einzelnen Typen finden sich im Abschnitt <a class="crosslink" href="#RAID-Level">RAID-Level</a>.</p></li><li><p>Soll von einem neuen RAID-Verbund gebootet werden (Root-Dateisystem), sollte zusätzlich der Abschnitt <a class="crosslink" href="#Bootloader">Bootloader</a> beachtet werden.</p></li></ul><p>
</p><div class="section_2"><h3 id="RAID-und-Backup">RAID und Backup<a class="headerlink" href="#RAID-und-Backup">¶</a></h3><p>
Ein RAID ersetzt keine Datensicherung! Auch wenn es verlockend scheint, z.B. ein RAID 1 mit externer USB-Festplatte aufzusetzen, um eine automatische Sicherung zu erhalten, ist dies kein Backup:
</p><ul><li><p>Das Entfernen der externen Festplatte führt immer dazu, dass sich das RAID im Fehlerzustand (degraded) befindet. Bei Wiederanschluss muss die interne Festplatte jedesmal komplett neu mit der externen Platte synchronisiert werden.</p></li><li><p>Ein RAID schützt ausschließlich vor Datenverlust durch Plattendefekte. Ein Datenverlust, der durch Fehler des  Betriebssystems, des Dateisystems, durch die verwendeten Programmen oder den Benutzer entsteht, wird sofort automatisch auf alle Laufwerke synchronisiert, so dass das vermeintliche Backup automatisch mit fehlerhaften Daten überschrieben wird.</p></li></ul><p>
</p></div><div class="section_2"><h3 id="IDE-SATA">IDE/SATA<a class="headerlink" href="#IDE-SATA">¶</a></h3><p>
Generell sollte man bei RAIDs moderne <a class="interwiki interwiki-wikipedia" href="https://de.wikipedia.org/wiki/SATA">SATA</a>-Festplatten<sup><a href="#source-1">[1]</a></sup> verwenden, da der Datendurchsatz bei diesen zum Teil erheblich höher ist als bei älteren IDE-Platten. Zudem sind SATA-Platten prinzipiell "hotplugable". Das heißt, sie sind im laufenden Betrieb eines RAIDs an- und abschaltbar und damit auch austauschbar. Allerdings sollte man genau wissen, was man tut, bevor man sich an solcherlei Aktionen heranwagt.</p><div class="box warning"><h3 class="box warning">Achtung!</h3><div class="contents"><p>Nicht jeder SATA-Controller ist in der Lage, mit "Hotplug" auch richtig umzugehen. Man sollte auch darauf achten, dass man die richtige Festplatte angibt, um Datenverlust zu vermeiden.
</p></div></div><p>Bei älteren <a class="interwiki interwiki-wikipedia" href="https://de.wikipedia.org/wiki/ATA/ATAPI">IDE-ATA</a>-Festplatten gilt: die verwendeten Festplatten sollten nicht am selben IDE-Kanal hängen, da im Fehlerfall einer Festplatte unter Umständen der komplette IDE-Kanal gestört wird und dadurch u.U. das RAID nicht mehr nutzbar ist. Bei einem RAID 0 erhöht sich die Gesamtleistung, da paralleles Lesen/Schreiben auf verschiedenen IDE-Kanälen schneller geht als auf nur einem.</p></div></div><div class="section_1"><h2 id="Installation">Installation<a class="headerlink" href="#Installation">¶</a></h2><p>
Folgende Pakete muss installiert<sup><a href="#source-2">[2]</a></sup> werden, um ein Software-RAID erstellen zu können:
</p><ul><li><p><strong>mdadm</strong></p></li><li><p><strong>parted</strong></p></li></ul><p><img alt="Wiki/Vorlagen/Installbutton/button.png" class="image-default" src="./_/fd60ccb86c4d96df2f4518df2936cc7d038467aa.png"/>
mit <a class="internal" href="./apturl.html">apturl</a>
</p><div class="package-list"><div class="contents"><p>
Paketliste zum Kopieren:
</p><div class="bash"><div class="contents"><pre class="notranslate">sudo apt-get install mdadm parted </pre></div></div><p>
</p><div class="bash"><div class="contents"><pre class="notranslate">sudo aptitude install mdadm parted </pre></div></div><p>
</p></div></div></div><div class="section_1"><h2 id="Anlegen-eines-RAID">Anlegen eines RAID<a class="headerlink" href="#Anlegen-eines-RAID">¶</a></h2><p>
</p><div class="section_2"><h3 id="Partitionierung">Partitionierung<a class="headerlink" href="#Partitionierung">¶</a></h3><p>
</p><div class="box warning"><h3 class="box warning">Achtung!</h3><div class="contents"><p>Veränderungen an den Festplatten löschen die vorherigen Inhalte der beteiligten Festplatten. Es ist daher dringend angeraten, vorher eine Datensicherung durchzuführen.
</p></div></div><p>
Zunächst müssen die Bezeichnungen der zu verwenden Festplatten bekannt sein<sup><a href="#source-3">[3]</a></sup>. Auf jeder Festplatte wird eine Partition erstellt, die (fast) den gesamten Platz der Platte einnimmt. Im Beispiel wird das Laufwerk <code class="notranslate">/dev/sde</code><sup><a href="#source-4">[4]</a></sup> vorbereitet. Die Schritte müssen für jedes Laufwerk, das am RAID teilnehmen soll, mit der entsprechenden Bezeichnung vom eigenen System wiederholt werden:</p><p>Eine neue, leere Partitionstabelle auf dem Laufwerk erstellen<sup><a href="#source-5">[5]</a></sup><sup><a href="#source-6">[6]</a></sup>Für neuere PCs mit UEFI Bios:
</p><div class="bash"><div class="contents"><pre class="notranslate">sudo parted /dev/sde mklabel gpt </pre></div></div><p>
Für ältere PCs mit altem Bios:
</p><div class="bash"><div class="contents"><pre class="notranslate">sudo parted /dev/sde mklabel msdos </pre></div></div><p>
Eine einzelne Partition erstellen:
</p><div class="bash"><div class="contents"><pre class="notranslate">sudo parted -a optimal -- /dev/sde mkpart primary 2048s -8192s  </pre></div></div><p>
Möchte man die gesamte Platte nutzen, gibt man statt "2048s -8192s" einfach "0% 100%" an.</p><p>Die neue Partition als RAID-Partition markieren:
</p><div class="bash"><div class="contents"><pre class="notranslate">sudo parted /dev/sde set 1 raid on </pre></div></div><div class="box notice"><h3 class="box notice">Hinweis:</h3><div class="contents"><p>
</p><ul><li><p>Es werden bewusst 8192 Sektoren am Ende der Festplatte ungenutzt gelassen, um für Ausfälle gewappnet zu sein. Falls nach Jahren keine baugleiche Festplatte mehr beschafft werden kann, ermöglicht es der frei gelassene Platz auch Laufwerke als Ersatz zu nehmen, die einige Sektoren weniger haben.</p></li><li><p>Am Anfang des Laufwerks werden 2048 Sektoren ungenutzt gelassen, um ein optimales <a class="crosslink" href="#Alignment">Alignment</a> zu ermöglichen. Über den Parameter <code class="notranslate">-a optimal</code> kümmert sich <strong>parted</strong> um weitere Anpassungen, falls nötig.</p></li><li><p>Es ist auch möglich, die Laufwerke unpartitioniert zusammenzufassen. Dies birgt jedoch einige Nachteile. Zunächst verkompliziert es das <a class="crosslink" href="#Alignment">Alignment</a> und kann damit zu Geschwindigkeitseinbußen führen. Außerdem kann im Falle eines Defekts nur ein Laufwerk mit genau gleicher oder höherer Sektorzahl als Ersatz benutzt werden.</p></li></ul></div></div></div><div class="section_2"><h3 id="RAID-anlegen">RAID anlegen<a class="headerlink" href="#RAID-anlegen">¶</a></h3><p>
Das Hauptwerkzeug für alle Arbeiten an Software-RAIDs unter Linux ist <strong>mdadm</strong>. Es bildet die Schnittstelle zu den RAID-Funktionen des Kernels. Mehr Informationen finden sich im Abschnitt <a class="crosslink" href="#MDADM">MDADM</a>. Hiermit werden auch RAID-Verbunde erstellt:</p><p>Beispiel 1: RAID 1 über zwei Partitionen, <strong>sde1</strong> und <strong>sdf1</strong>:
</p><div class="bash"><div class="contents"><pre class="notranslate">sudo mdadm --create /dev/md0 --auto md --level=1 --raid-devices=2 /dev/sde1 /dev/sdf1 </pre></div></div><p>Beispiel 2: Software-RAID 5 mit 4 Partitionen:
</p><div class="bash"><div class="contents"><pre class="notranslate">sudo mdadm --create /dev/md0 --auto md --level=5 --raid-devices=4 /dev/sde1 /dev/sdf1 /dev/sdg1 /dev/sdh1 </pre></div></div><p>Die Parameter im Einzelnen:
</p><ul><li><p><code class="notranslate">--create /dev/md0</code> - Erzeugt ein neues Verbundgerät unter der Bezeichnung <strong>md0</strong>. Falls bereits Verbundgeräte vorhanden sind, muss ein anderer freier Bezeichner gewählt werden (<em>md1</em>,<em>md2</em>, etc.).</p></li><li><p><code class="notranslate">--auto md</code> - Erzeugt ein "klassisches" Verbundgerät ohne Vor-Partitionierung (diese können bei Bedarf ab Kernelversion 2.6.28 trotzdem partitioniert werden).</p></li><li><p><code class="notranslate">--level=</code> - Die Art des RAID-Verbundes. RAID 1 im ersten Beispiel, im zweiten RAID 5. Eine Übersicht über die möglichen RAID-Level gibt die <a class="crosslink" href="#RAID-Level">Tabelle RAID-Level</a></p></li><li><p><code class="notranslate">--raid-devices</code> - Die Anzahl der Einzelgeräte, aus denen das RAID bestehen soll.</p></li><li><p><code class="notranslate">/dev/sde1 /dev/sde2 ...</code> - Die einzelnen Geräte<sup><a href="#source-6">[6]</a></sup>, die zusammengefasst werden sollen. Die Reihenfolge der Bezeichner, bzw. idealerweise die der entsprechenden physischen Geräte sollte man sich aufschreiben, falls im Notfall das RAID von Hand neu zusammengesetzt werden muss.</p></li></ul><p>
Die nötigen <a class="crosslink" href="#RAID-Zustaende">Initialisierungsmaßnahmen</a> laufen nun selbstständig im Hintergrund ab. Das neu erstellte Blockgerät <strong>md0</strong> kann jedoch sofort benutzt werden und das System darf auch währenddessen normal heruntergefahren oder neu gestartet werden.</p></div><div class="section_2"><h3 id="Dateisystem">Dateisystem<a class="headerlink" href="#Dateisystem">¶</a></h3><p>
Um den RAID-Verbund als normales Speicherlaufwerk zu nutzen, muss noch ein Dateisystem<sup><a href="#source-7">[7]</a></sup> darauf erstellt und dieses ins System eingebunden werden, z.B. <a class="internal" href="./ext.html">ext4</a>. Im Falle eines RAID 1 ist dies recht einfach:</p><div class="bash"><div class="contents"><pre class="notranslate">sudo mkfs.ext4 /dev/md0 </pre></div></div><p>Bei komplexeren Verbunden wie RAID 0, 5, 6 oder 10 sollte das Dateisystem auf das RAID angepasst werden, um optimale Leistung zu ermöglichen. Dafür muss zunächst die sog. "Chunk Size", also die Datenmenge, die in einem einzelnen Schreibvorgang geschrieben wird, bekannt sein. Diese lässt sich wie folgt ermitteln:</p><div class="bash"><div class="contents"><pre class="notranslate">sudo mdadm -D /dev/md0 | grep "Chunk Size" </pre></div></div><p>
Bei einem RAID 5 mit Standardeinstellungen liefert dies Beispielsweise:</p><pre class="notranslate">     Chunk Size : 512K</pre><p>
Es werden also 512 KiB Chunks verwendet. Hieraus können, zusammen mit der Anzahl der Partitionen und des RAID-Levels, die Dateisystem-Parameter berechnet werden. Am einfachsten geht das mittels des <a class="external" href="http://busybox.net/~aldot/mkfs_stride.html" rel="nofollow">Raid Stride Calculators</a> <img alt="{en}" src="./_/d5ecf89114b079f85d02099649c4ee617ffa34c7.png"/>. Alternativ können die Parameter auch von Hand ermittelt werden:</p><ul><li><p><code class="notranslate">block-size</code> - Die Größe der Dateisystemblöcke in Bytes. Heutzutage werden fast ausschließlich 4096 Byte (4 KiB) Blöcke verwendet.</p></li><li><p><code class="notranslate">stride-size</code> - Die Chunk Size umgerechnet in Dateisystemblöcke. Bei 512 KiB Chunk Size mit 4 KiB Blöcken ergibt sich (512 KiB/ 4 KiB) = 128.</p></li><li><p><code class="notranslate">stripe-width</code> - Die Größe eines Datenstreifens, also die Menge an Blöcken, die geschrieben wird, wenn ein voller Chunk auf jedes Laufwerk geschrieben wird. Diese berechnet sich aus (<code class="notranslate">stride-size</code> * Anzahl der effektiv nutzbaren Partitionen). Bei einem RAID 5 über 4 Partitionen ergibt sich beispielsweise (128 * 3) = 384. Details zur Anzahl der effektiv nutzbaren Partitionen finden sich im Abschnitt <a class="crosslink" href="#RAID-Level">RAID-Level</a>.</p></li></ul><p>
Sind die Parameter ermittelt, wird das Dateisystem erstellt:
</p><div class="bash"><div class="contents"><pre class="notranslate">sudo mkfs.ext4 -b 4096 -E stride=128,stripe-width=384 /dev/md0 </pre></div></div><div class="section_3"><h4 id="RAID-mounten">RAID mounten<a class="headerlink" href="#RAID-mounten">¶</a></h4><p>
Das RAID muss noch in die <a class="internal" href="./verzeichnisstruktur.html">Verzeichnisstruktur</a> eingebunden<sup><a href="#source-8">[8]</a></sup> werden. Dies geschieht einfach mittels <code class="notranslate">mount</code>, z.B. am Mountpunkt <strong>/media/daten</strong>.</p><div class="bash"><div class="contents"><pre class="notranslate">sudo mount /dev/md0 /media/daten </pre></div></div><p>Damit das System beim Start das Dateisystem selber einhängt, muss eine entsprechende Zeile in die Datei <strong>/etc/fstab</strong><sup><a href="#source-9">[9]</a></sup> eingetragen werden:</p><pre class="notranslate">/dev/md0     /media/daten      ext4      defaults 0 2</pre></div></div><div class="section_2"><h3 id="mdadm-conf-aktualisieren">mdadm.conf aktualisieren<a class="headerlink" href="#mdadm-conf-aktualisieren">¶</a></h3><p>
Alle Informationen zum RAID werden auf jeder verwendeten Partition in den sog. Superblock geschrieben. Der Kernel sucht beim Starten automatisch nach diesen Superblöcken und startet alle voll funktionsfähigen RAIDs, ohne das eine Konfigurationsdatei nötig ist. Trotzdem kann es sinnvoll sein, eine Konfigurationsdatei zu erstellen, z.B. wenn man über Ausfälle am RAID per E-Mail benachrichtigt werden möchte. Die Konfigurationsdatei kann bequem mit einem Skript von mdadm erstellt werden und enthält dann direkt alle Definitionen aller momentan aktiven RAIDs:</p><div class="bash"><div class="contents"><pre class="notranslate">sudo su -c "/usr/share/mdadm/mkconf &gt; /etc/mdadm/mdadm.conf" </pre></div></div><div class="box warning"><h3 class="box warning">Achtung!</h3><div class="contents"><p>Je nach Konfiguration kommt es zu Fehlern in der mdadm.conf. Daher ist es sinnvoll diese zu überprüfen. Typische Fehler sind, wenn das RAID-System nicht wie im Beispiel als md0 sondern als md127 nach einem Neustart angezeigt wird. Das System kommt mit der Option "-name" in der mdadm.conf nicht klar. Diese Option auskommentieren und System neu starten. 
</p></div></div><p>Um bei Ausfällen per E-Mail benachrichtigt zu werden, muss in der neuen Datei <strong>/etc/mdadm/mdadm.conf</strong> die Zeile
</p><pre class="notranslate">MAILADDR root</pre><p>
<code class="notranslate">root</code> durch die gewünschte E-Mail-Adresse ersetzt werden. Dafür muss der E-Mail-Versand durch das System eingerichtet sein, z.B. via <a class="internal" href="./postfix.html">Postfix</a> als Satellitensystem.</p><p>Über die Konfigurationsdatei können sehr viele Details der RAIDs angepasst werden, nähere Informationen liefert die [Manpage] von mdadm.conf. Generell gilt bei neu aufgesetzten RAIDs allerdings: Je weniger, desto besser. In den neueren Superblock-Formaten (neuer als Superblock-Version 0.90) werden alle wichtigen Informationen direkt auf den beteiligten Partitionen gespeichert, auch wenn nachträglich Änderungen vorgenommen werden. Andererseits haben die Parameter aus der mdadm.conf Vorrang. So ist es z.B. möglich, alle am RAID beteiligten Partitionen in der Datei anzugeben. Ändert sich jedoch die Reihenfolge der Festplatten (z.B. bei Austausch des Controllers, Umstecken der Kabel, Anschließen eines USB-Sticks etc.) ließe sich das RAID nicht mehr Starten, obwohl in den Superblöcken die richtigen Positionen der Laufwerk (unabhängig von den Buchstabenbezeichnungen) gespeichert sind, bevor nicht die gegenläufige Angabe in der mdadm.conf geändert oder explizit übergangen wird.</p><p>Damit die Konfiguration beim Booten verfügbar ist, muss schließlich noch die Initrd aktualisiert werden:</p><div class="bash"><div class="contents"><pre class="notranslate">sudo update-initramfs -u -k all </pre></div></div></div></div><div class="section_1"><h2 id="Wartung">Wartung<a class="headerlink" href="#Wartung">¶</a></h2><p>
Einige der folgenden Punkte kann man man auch mit der GUI der Laufwerksverwaltung <strong>palimpsest</strong> aus dem Paket <strong>gnome-disk-utility</strong> machen. Man geht dort in der linken Spalte auf die gewünschte RAID-Anordnung und kann dann in der rechten Spalte im Punkt "Komponenten bearbeiten" die gewünschten Aktionen veranlassen.</p><div class="section_2"><h3 id="RAID-ueberwachen">RAID überwachen<a class="headerlink" href="#RAID-ueberwachen">¶</a></h3><p>
Eine Kurzzusammenfassung für alle RAIDs erhält man mittels</p><div class="bash"><div class="contents"><pre class="notranslate">cat /proc/mdstat </pre></div></div><p>Eine Beispielausgabe eines Systems mit mehreren RAID-Verbünden ohne Ausfälle:
</p><pre class="notranslate">Personalities : [raid6] [raid5] [raid4] [raid1] [linear] [multipath] [raid0] [raid10]
md1 : active raid1 sde5[0] sdf5[1]
      195114936 blocks super 1.2 [2/2] [UU]

md0 : active raid1 sdf1[1] sde1[0]
      242676 blocks super 1.2 [2/2] [UU]

md2 : active raid6 sdg1[4] sdh1[5] sdi1[6] sdj1[7] sda1[0] sdd1[3] sdb1[1] sdc1[2]
      2930304000 blocks super 1.2 level 6, 512k chunk, algorithm 2 [8/8] [UUUUUUUU]</pre><p>
Das Beispiel zeigt zwei RAID 1 (<code class="notranslate">md0</code> und <code class="notranslate">md1</code>) mit je zwei Partitionen und ein RAID 6 (<code class="notranslate">md2</code>) mit 8 Partitionen. In der jeweils zweiten Zeile wird am Ende in eckigen Klammern der Zustand der einzelnen Partitionen angezeigt, wobei ein <code class="notranslate">U</code> bedeutet, dass das jeweilige Gerät in Ordnung (up) ist. Ausführliche Informationen zu einem RAID-Device liefert:</p><div class="bash"><div class="contents"><pre class="notranslate">sudo mdadm --detail /dev/md0 </pre></div></div></div><div class="section_2"><h3 id="Hotspare-hinzufuegen">Hotspare hinzufügen<a class="headerlink" href="#Hotspare-hinzufuegen">¶</a></h3><p>
Ein RAID kann Ersatzplatten vorhalten und diese beim Ausfall einer anderen Festplatte automatisch als Ersatz nutzen. Solche Platten werden als Hotspares, oft auch einfach nur Spare, bezeichnet. Um eine Platte als Spare zu nutzen, muss diese zunächst entsprechend <a class="crosslink" href="#Raid-anlegen">partitioniert</a> werden. Danach kann diese zum Verbund hinzugefügt werden, hier am Beispiel des eingänglichen beschriebenen RAID 5 und einer neuen Partition <strong>/dev/sdi1</strong>:</p><div class="bash"><div class="contents"><pre class="notranslate">mdadm /dev/md0 --add /dev/sdi1 </pre></div></div><p>
Falls nun eine Partition ausfallen sollte, startet automatisch ein <a class="crosslink" href="#Rebuild-und-Resync">Rebuild</a>, die Spare-Partition wird dabei aktiviert und als Ersatz für die ausgefallene Partition genutzt.</p></div><div class="section_2"><h3 id="Festplattenausfall">Festplattenausfall<a class="headerlink" href="#Festplattenausfall">¶</a></h3><p>
</p><div class="section_3"><h4 id="Details-ermitteln">Details ermitteln<a class="headerlink" href="#Details-ermitteln">¶</a></h4><p>
Dieses Beispiel zeigt eine ausgefallene Platte in einem RAID 6.</p><pre class="notranslate">Personalities : [raid6] [raid5] [raid4] [raid1] [linear] [multipath] [raid0] [raid10]
md2 : active raid6 sdj1[7] sdi1[6] sdh1[5] sdg1[4] sdd1[3] sda1[0] sdb1[1] sdc1[2]
      3418688000 blocks super 1.2 level 6, 512k chunk, algorithm 2 [9/8] [UUUUUUUU_]

unused devices: &lt;none&gt;</pre><p>
In diesem Fall wurde das fehlerhafte Gerät bereits automatisch entfernt. Genauere Details, u.a. den Namen des defekten Geräts kann mit <strong>mdadm</strong> ermittelt werden:</p><div class="bash"><div class="contents"><pre class="notranslate">sudo mdadm --detail /dev/md2 </pre></div></div></div><div class="section_3"><h4 id="Festplatte-wechseln">Festplatte wechseln<a class="headerlink" href="#Festplatte-wechseln">¶</a></h4><p>
</p><div class="box warning"><h3 class="box warning">Achtung!</h3><div class="contents"><p>Bei einem RAID 0 äußert sich der Ausfall einer Platte im Totalausfall des gesamten RAID-Verbunds. Das RAID 0 kann daher nicht mit den folgenden Anweisungen repariert werden, sondern muss neu aufgesetzt werden und die hoffentlich vorhandene Datensicherung eingespielt werden.
</p></div></div><p>
Ist das defekte Gerät (hier im Beispiel <code class="notranslate">/dev/sdk1</code>) ermittelt, kann die entsprechende Festplatte ausgetauscht werden:</p><ol class="arabic"><li><p>Falls der Kernel das Gerät noch nicht aus dem Verbund entfernt hat (d.h. es wird beim Befehl <code class="notranslate">mdadm --detail</code> noch aufgeführt), muss es zunächst aus dem Verbund entfernt werden:</p><div class="bash"><div class="contents"><pre class="notranslate">sudo mdadm /dev/md2 --remove /dev/sdk1 </pre></div></div></li><li><p>Nun kann die entsprechende Platte gewechselt werden. Ist eine entsprechende Austauschplatte eingebaut, muss diese zunächst partitioniert werden. Die neue Partition muss mindestens die gleiche Anzahl an Sektoren aufweisen, wie die bereits genutzten Partitionen. Von einer bestehenden Platte erhält man die Sektorenzahl der Partitionen (hier am Beispiel von <code class="notranslate">/dev/sda</code>) mittels: </p><div class="bash"><div class="contents"><pre class="notranslate">sudo parted /dev/sda u s print  </pre></div></div></li><li><p>Ist die neue Platte entsprechend partitioniert, wird die neue Partition zum RAID-Verbund hinzugefügt (hier am Beispielaustausch von <code class="notranslate">/dev/sdk1</code> in <code class="notranslate">/dev/md2</code>):</p><div class="bash"><div class="contents"><pre class="notranslate">sudo mdadm /dev/md2 --add /dev/sdk1 </pre></div></div></li></ol><p>
Im Hintergrund beginnt nun ein <a class="crosslink" href="#RAID-Zustaende">Rebuild</a>, aus den noch vorhandenen Partitionen wird also der Inhalt für die neue Partition berechnet und geschrieben. Je nach RAID-Level und Größe dauert ein Rebuild mehrere Stunden bis Tage. Das System darf währenddessen neu gestartet oder heruntergefahren werden. Ein Systemabsturz kann jedoch zu Datenverlust führen. Manchmal lässt sich der Vorgang <a class="crosslink" href="#Resync-und-Rebuild-beschleunigen">beschleunigen</a>.</p><div class="box notice"><h3 class="box notice">Hinweis:</h3><div class="contents"><p>Wurden Partitionen einer Platte von verschiedenen RAIDs genutzt, dann kann es vorkommen, dass eine verwendete Festplatte teilweise defekt ist und sich z.B. die Partition von <code class="notranslate">md0</code> im Status <code class="notranslate">[U_]</code> befindet, während alle anderen im Status <code class="notranslate">[UU]</code> sind. In diesem Fall müssen diese mit dem Befehl:</p><div class="bash"><div class="contents"><pre class="notranslate">mdadm /dev/mdX --fail /dev/sdXY </pre></div></div><p>alle einzeln in den Modus <code class="notranslate">[U_]</code> versetzt werden.
</p></div></div></div></div><div class="section_2"><h3 id="Controller-Fehler">Controller-Fehler<a class="headerlink" href="#Controller-Fehler">¶</a></h3><p>
In Einzelfällen kann es vorkommen, dass aufgrund eines defekten Netzteils (oder Controller) ein RAID nicht mehr funktionsfähig ist. In so einem Fall liegt oft kein Schaden an den Festplatten vor und das Problem kann mit der folgenden Vorgehensweise behoben werden:
</p><ol class="arabic"><li><p>RAID stoppen:</p><div class="bash"><div class="contents"><pre class="notranslate">sudo mdadm --stop /dev/md0 </pre></div></div></li><li><p>Das RAID muss manuell wieder zusammengefügt werden, dabei ist es wichtig, die letzte funktionierende Konfiguration zu verwenden. Bei dem <a class="crosslink" href="#RAID-anlegen">o.g. Beispiel</a>, ein RAID 5 mit 4 Partitionen, bei dem zwei Festplatte wegen Controller-Defekt ausgestiegen sind, müssen die ersten zwei Partitionen verwendet werden, da sie bis zum Ausfall noch zusammen aktiv waren. Nun reaktiviert man das Arrays mit: </p><div class="bash"><div class="contents"><pre class="notranslate">sudo mdadm --assemble /dev/md0 /dev/sde1 /dev/sdf1 --force </pre></div></div><p>. </p></li><li><p>Die weiteren Partitionen können nun mit:</p><div class="bash"><div class="contents"><pre class="notranslate">sudo mdadm --re-add /dev/md0 /dev/sdg1 /dev/sdh1 </pre></div></div><p> wieder in den Verbund aufgenommen werden. </p></li></ol><p>
</p></div><div class="section_2"><h3 id="RAID-erweitern">RAID erweitern<a class="headerlink" href="#RAID-erweitern">¶</a></h3><p>
Falls zum Beispiel der Speicherplatz eines RAIDs nicht mehr ausreicht, kann man es durch weitere Festplatten bzw. Partitionen erweitern. Dies gilt allerdings nur für ein RAID 1, 5 oder 6. Das RAID darf während des Vorgangs <a class="crosslink" href="#RAID-mounten">eingebunden</a> sein. Die neue Partition muss zunächst wie oben beschrieben als <a class="crosslink" href="#Hotspare-hinzufuegen">Hotspare</a> hinzugefügt werden. Danach kann das RAID um das neue Laufwerk erweitert werden:</p><ol class="arabic"><li><p>Das RAID neu aufbauen, um somit den neuen Speicherplatz nutzen zu können: </p><div class="bash"><div class="contents"><pre class="notranslate">sudo mdadm --grow --raid-devices=5 /dev/md0 --backup-file=/tmp/md0.bak </pre></div></div><p> Die Option <code class="notranslate">raid-devices</code> gibt dabei die Anzahl der Geräte an, aus denen das RAID nach der Erweiterung bestehen soll. In der mittels <code class="notranslate">backup-file</code> angegebenen Datei werden kritische Bereiche gesichert (typischerweise einige wenige MiB). Falls das System während der Erweiterung abstürzt, kann die Erweiterung später mittels </p><div class="bash"><div class="contents"><pre class="notranslate">sudo mdadm /dev/md0 --continue --backup-file=/tmp/md0.bak </pre></div></div><p> fortgesetzt werden. Die Sicherungsdatei darf nicht auf dem zu erweiternden RAID liegen! Die Verwendung von <code class="notranslate">backup-file</code> ist zwar nicht zwingend notwendig, wird aber dringend empfohlen.</p></li><li><p>Das Dateisystem muss noch <a class="internal" href="./dateisystem.html">erweitert</a> werden, damit der neu entstandene Speicherplatz genutzt werden kann. Das Dateisystem sollte dabei, wenn möglich, nicht eingehangen sein. Bei <a class="internal" href="./ext.html">ext</a>-Dateisystemen muss außerdem vorher eine Überprüfung durchgeführt werden. Am Beispiel von <a class="internal" href="./ext.html#ext4">ext4</a>: </p><div class="bash"><div class="contents"><pre class="notranslate">sudo umount /dev/md0           # Das Dateisystem aushängen
sudo fsck.ext4 -f /dev/md0     # Die Prüfung erzwingen, selbst wenn vor Kurzem geprüft wurde
sudo resize2fs /dev/md0        # Das Dateisystem auf Maximalgröße erweitern
sudo mount /dev/md0            # Das Dateisystem wieder einhängen </pre></div></div></li><li><p>Die <a class="crosslink" href="#mdadm-conf-aktualisieren">mdadm.conf</a> sollte noch auf den aktuellen Stand gebracht werden (evtl. alte Einträge löschen).</p></li><li><p>Der Status lässt sich wieder jederzeit <a class="crosslink" href="#RAID-ueberwachen">einsehen</a>.</p></li></ol><p>
</p></div></div><div class="section_1"><h2 id="Begriffe-und-Details">Begriffe und Details<a class="headerlink" href="#Begriffe-und-Details">¶</a></h2><p>
</p><div class="section_2"><h3 id="RAID-Level">RAID-Level<a class="headerlink" href="#RAID-Level">¶</a></h3><p>
Eine Übersicht über die gebräuchlichen und unterstützten RAID-Level. Bei der Angabe des Speicherplatzes im RAID bezeichnet <em>k</em>  die Kapazität je Partition und <em>n</em> die Anzahl der verwendeten Partitionen.</p><table><tr class="titel"><td colspan="5"> Auswahl von RAID-Typen im Überblick </td></tr><tr class="kopf"><td style="width: 2%">Typ </td><td style="text-align: center; width: 10%"> mind. Partitionen </td><td style="text-align: center">  Speicher-<br/>platz </td><td> Vorteil </td><td> Bemerkung </td></tr><tr><td style="text-align: right"> 0  </td><td style="text-align: center"> 2  </td><td style="text-align: center; width: 5%">k*n  </td><td> Geschwindigkeit (Lesen &amp; Schreiben), Plattenplatz </td><td> Keine Partition darf ausfallen, deshalb ein Zweck des RAID nicht erreicht - Reißverschlussverfahren </td></tr><tr><td style="text-align: right"> 1  </td><td style="text-align: center"> 2  </td><td style="text-align: center">k  </td><td> Ausfallsicherheit, Geschwindigkeit (Lesen) </td><td> Alle bis auf eine Partition dürfen ausfallen - Spiegelung </td></tr><tr><td style="text-align: right"> 5  </td><td style="text-align: center"> 3  </td><td style="text-align: center">k*(n-1)  </td><td> Plattenplatz, Ausfallsicherheit, Geschwindigkeit (Lesen) </td><td> Eine Partition darf ausfallen - Striping &amp; Parität</td></tr><tr><td style="text-align: right"> 6  </td><td style="text-align: center"> 4  </td><td style="text-align: center">k*(n-2)  </td><td> Plattenplatz, bessere Ausfallsicherheit als RAID 5, Geschwindigkeit (Lesen) </td><td> Zwei Partitionen dürfen ausfallen - Striping &amp; doppelte Parität </td></tr><tr><td style="text-align: right"> 10  </td><td style="text-align: center"> 4  </td><td style="text-align: center"> </td><td> Sicherheit und gesteigerte Schreib-/Lesegeschwindigkeit. </td><td> Kombination aus RAID 0 über mehrere RAID 1 </td></tr><tr class="highlight"><td colspan="5"> RAID unterstützt auch unbenutzte Reservelaufwerke, sog. <a class="crosslink" href="#Hotspare-hinzufuegen">Hotspares</a>. Dabei werden vorab Partitionen bekannt gegeben, die beim Ausfall eines Laufwerks innerhalb des RAID-Verbundes durch das Reservelaufwerk automatisch ersetzt werden.</td></tr></table><p>
</p></div><div class="section_2"><h3 id="RAID-Zustaende">RAID-Zustände<a class="headerlink" href="#RAID-Zustaende">¶</a></h3><p>
Ein RAID kann sich in unterschiedlichen Zuständen befinden, die seinen Status zusammenfassen:</p><table><tr class="titel"><td colspan="2"> RAID-Zustände im Überblick </td></tr><tr class="kopf"><td> Zustand </td><td> Beschreibung </td></tr><tr><td style="width: 10%">Clean </td><td> Bezeichnet den Normalzustand. Es liegt kein Fehler vor und alle Prüf- und Initialisierungsaufgaben sind abgeschlossen. </td></tr><tr><td>Degraded </td><td> Es liegt ein Ausfall vor. Je nach <a class="crosslink" href="#RAID-Level">RAID-Level</a> kann dieser durch <a class="crosslink" href="#Festplattenausfall">Austausch</a> einer Festplatte mit einem anschließenden Rebuild behoben werden um das RAID wieder in den Clean-Zustand zu versetzen.</td></tr><tr><td> Resync </td><td> Bei einem Resync werden je nach RAID-Level Sicherungsinformation, z.B. Paritäten, geprüft und ggf. neu erstellt. Ein neu angelegtes RAID befindet sich in der Regel in diesem Zustand. Auch während eines Resync sind die Daten auf dem RAID bereits vor einem Ausfall gesichert. Die volle Lese- und Schreibgeschwindigkeit kann jedoch erst nach Abschluss des Resync erreicht werden. </td></tr><tr><td> Rebuild </td><td> Bei einem Rebuild "erholt" sich das RAID von einem Ausfall. Die verlorenen Daten werden aus den Sicherungsinformationen wiederhergestellt und damit das Austauschlaufwerk gefüllt. Ein weiterer Ausfall eines Laufwerks während eines Rebuilds wird in der Regel zu Datenverlust führen. </td></tr></table><p>Resync und Rebuild können je nach Größe und Art des RAIDs mehrere Stunden bis Tage in Anspruch nehmen. Unter Umständen lassen sich die Vorgänge <a class="crosslink" href="#Resync-und-Rebuild-beschleunigen">beschleunigen</a>.</p><div class="box experts"><h3 class="box experts">Experten-Info:</h3><div class="contents"><p>Da Rebuilds eine intensive Datenträgernutzung bedeuten, passiert es des Öfteren, das sich die noch funktionierende(n) Platte(n) ebenfalls ausfällt(ausfallen). Bei unternehmenskritischen Daten sollte man bereits beim Kauf der Komponenten auf hohe Qualität achten.
</p></div></div></div><div class="section_2"><h3 id="Alignment">Alignment<a class="headerlink" href="#Alignment">¶</a></h3><p>
Festplatten, RAID-Verbunde und Dateisysteme fassen Daten jeweils für sich in Blöcke zusammen, bevor sie gespeichert werden. Diese Blöcke haben im Allgemeinen alle unterschiedliche Größen. Ein Beispiel für das Lesen einer sehr kleinen Datei:</p><ol class="arabic"><li><p>Das Dateisystem möchte einen einzelnen 4 KiB großen Block lesen</p></li><li><p>Das RAID muss dafür den oder die  512 KiB großen RAID-Blöcke (bei RAIDS oft <code class="notranslate">Chunks</code> genannt) laden, in denen der Dateisystem-Block abgelegt ist.</p></li><li><p>Die Festplatten müssen dafür wiederum alle 512 Byte großen Blöcke (hier meist <code class="notranslate">Sektoren</code> genannt) laden, die am entsprechenden RAID-Block beteiligt sind.</p></li></ol><p>
Im Idealfall muss also das RAID nur einen 512 KiB Block laden und die Festplatten dafür 1024 Blöcke (512 KiB = 512 B * 1024). Dafür müssen diese geschachtelten Blöcke jedoch aufeinander ausgerichtet sein.</p><p>Im schlechtesten Fall könnte ein Dateisystem-Block kurz vor dem Ende eines RAID-Blocks liegen, so dass für einen Dateisystem-Block zwei RAID-Blöcke geladen werden müssen. Analog könnte ein RAID-Block auch 1025 anstatt 1024 Festplatten-Blöcke belegen, falls er mitten in einem Festplatten-Block anfängt.</p><p>Das Lesen eines Dateisystem-Blocks würde damit im schlechtesten Fall das Laden von 2050 Festplatten-Blöcken erfordern. Dies führt zu dramatischen Performance-Einbußen schon beim Lesen. Da beim Schreiben oft auch zuerst die vorherigen Daten gelesen werden müssen, sind die Einbußen beim Schreiben noch stärker.</p><p>Daher sollte bei der Verwendung von Blockgeräten immer auf das Alignment, also die Ausrichtung der verschiedenen Block-Arten aufeinander, geachtet werden:</p><ul><li><p>Der erste Dateisystem-Block eines RAID-Blocks sollte genau am Anfang des RAID-Blocks beginnen.</p></li><li><p>Ein RAID-Block sollte genau am Anfang eines Festplatten-Blocks beginnen.</p></li><li><p>Die Größe der RAID-Blöcke sollte ein ganzzahliges Vielfaches der Dateisystem-Blöcke sein.</p></li><li><p>Die Größe der RAID-Blöcke sollte ein ganzzahliges Vielfaches der Festplatten-Blöcke sein.</p></li><li><p>Partitionen sollten auf Sektorgrenzen der Festplatten ausgerichtet sein, wie im Abschnitt <a class="crosslink" href="#Partitionierung">Partitionierung</a> beschrieben.</p></li><li><p>Dem Dateisystem sollten Informationen zum unterliegenden RAID <a class="crosslink" href="#Dateisystem">bereitgestellt werden</a>, um seine Blöcke passend auszurichten.</p></li></ul><p>
Falls noch weitere Schichten zwischen Dateisystem und Festplatte verwendet werden, z.B. bei Verschlüsselung, muss auch bei diesen auf das Alignment geachtet werden.</p></div><div class="section_2"><h3 id="MDADM">MDADM<a class="headerlink" href="#MDADM">¶</a></h3><p>
<strong>mdadm</strong> ist das Administrator-Werkzeug für alle Arbeiten an Software-RAIDs. Durch die Angabe eines Schlüsselwortes wird ein bestimmter Modus eingeleitet, der für die ordnungsgemäße Verarbeitung der weiteren Optionen entscheidend ist. Eine komplette Beschreibung zu Modi und Optionen befindet sich in der <a class="internal" href="./man.html">Manpage</a> zu <strong>mdadm</strong>.</p><div class="bash"><div class="contents"><pre class="notranslate">mdadm OPTIONEN </pre></div></div><p>
</p><table style="width: 100%"><tr class="titel"><td colspan="4">Syntax-Übersicht der Modi </td></tr><tr class="kopf"><td>Nr. </td><td style="width: 33%">Syntax </td><td style="width: 5%">Modus </td><td> Kurzbeschreibung </td></tr><tr><td style="width: 2%">1 </td><td class="befehl">mdadm --assemble MD-DEVICE OPTIONS DEVICES </td><td rowspan="3">Assemble </td><td> Assembliert das Array mit den angegebenen Festplatten/Partitionen </td></tr><tr><td> 1.1 </td><td class="befehl">mdadm --assemble --scan MD-DEVICE OPTIONS </td><td> Assembliert das angegebene Array neu anhand der Superblöcke  </td></tr><tr><td> 1.2 </td><td class="befehl">mdadm --assemble --scan OPTIONS </td><td> Assembliert alle Arrays anhand der Superblöcke auf den Partitionen </td></tr><tr class="highlight"><td> 2. </td><td class="befehl">mdadm --create MD-DEVICE OPTIONS DEVICES </td><td> Build </td><td> Anlegen/Definieren eines neues Arrays </td></tr><tr><td> 3. </td><td class="befehl">mdadm --grow MD-DEVICE OPTIONS </td><td> Grow </td><td> Vergrößern/Verkleinern eines bestehenden Arrays </td></tr><tr class="highlight"><td> 4. </td><td class="befehl">mdadm --monitor MD-DEVICE OPTIONS DEVICES </td><td> Monitor </td><td> Monitoring von einem oder allen <em>md-devices</em>, inkl. Reaktion auf Status-Veränderungen </td></tr><tr><td> 5. </td><td class="befehl">mdadm MD-DEVICE OPTIONS DEVICES </td><td>  Manage </td><td> Verwaltung eines RAIDs </td></tr><tr class="highlight"><td> 6. </td><td class="befehl">mdadm OPTIONS DEVICES </td><td> Misc </td><td> Sonstige Aufgaben </td></tr><tr><td style="border-right: none"> </td><td colspan="3" style="border-left: none"> Legende: <code class="notranslate">MD-DEVICES</code><sup><a href="#source-4">[4]</a></sup> beschreibt die RAID-Arrays und <code class="notranslate">DEVICES</code> die am Array teilnehmenden Festplatten/Partitionen<sup><a href="#source-5">[5]</a></sup> </td></tr></table><p>
</p><div class="section_3"><h4 id="Optionen">Optionen<a class="headerlink" href="#Optionen">¶</a></h4><p>
Neben dem einzelnen Modus gibt es eine ganze Reihe von Optionen, die unterschiedliche Funktionen bei den einzelnen Modi haben. Eine komplette Beschreibung zu Modus und Optionen befindet sich in der <a class="internal" href="./man.html">Manpage</a> zu <strong>mdadm</strong>.</p><table style="width: 100%"><tr class="titel"><td colspan="4">Auswahl einiger Optionen mit dem zugeordneten <a class="crosslink" href="#Syntax">Modus</a>, wie er in den Beispielen angewendet wird. </td></tr><tr class="kopf"><td> Option </td><td> Beschreibung </td><td> gültig bei Modi </td></tr><tr><td> <code class="notranslate">--add</code> </td><td> Hinzufügen weiterer Festplatten/Partitionen </td><td> 1, 6 </td></tr><tr><td> <code class="notranslate">--backup-file=...</code> </td><td> Erzeugt eine Backup-Datei - darf nicht im Array liegen  </td><td> 1, 3  </td></tr><tr class="highlight"><td><code class="notranslate">--detail</code> </td><td> Details zu den Arrays ausgeben  </td><td> 6 </td></tr><tr><td> <code class="notranslate">--fail</code> </td><td> Status eines Array verändern  </td><td> 5 </td></tr><tr class="highlight"><td><code class="notranslate">--force</code> </td><td> Erzwinge die Ausführung, auch wenn es unsinnig erscheint </td><td> 1, 2, 6 </td></tr><tr><td> <code class="notranslate">--help</code> </td><td> 	Ausgabe eines generellen Hilfetextes - hinter eine Option gestellt = spezielle Optionshilfe  </td><td> 1, 2, 3, 4, 5, 6 </td></tr><tr class="highlight"><td><code class="notranslate">--level=...</code> </td><td> Bezeichnet den RAID-Typ  </td><td> 1, 2, 3 </td></tr><tr><td> <code class="notranslate">--query</code> </td><td> Überprüfen, ob das angegebene Device ein <code class="notranslate">md</code>-Device ist bzw. zu einem Array gehört(e)  </td><td> 6 </td></tr><tr class="highlight"><td><code class="notranslate">--raid-device=...</code> </td><td> Anzahl der aktiven am Array teilnehmenden Festplatten/Partitionen  </td><td> 1, 2 </td></tr><tr><td> <code class="notranslate">--remove</code> </td><td> Festplatten/Partitionen die aus dem Array entnommen werden sollen </td><td> 5 </td></tr><tr class="highlight"><td><code class="notranslate">--stop</code> </td><td> Stoppen eines Arrays </td><td> 4, 5, 6 </td></tr><tr><td> <code class="notranslate">--spare-device=...</code> </td><td> Anzahl der inaktiven (Ersatz-) Festplatten/Partitionen eines Arrays  </td><td> 2, 3 </td></tr><tr class="highlight"><td><code class="notranslate">--test</code> </td><td> Testen der angegebenen Optionen  </td><td> 5, 6  </td></tr><tr><td> <code class="notranslate">--uuid=...</code> </td><td> Die <a class="internal" href="./uuid.html">UUID</a> des Arrays  </td><td> 1  </td></tr><tr class="highlight"><td><code class="notranslate">--verbose</code> </td><td> Mehr Ausgabe-Informationen erzeugen - kann 2x gesetzt werden </td><td> 4, 5, 6  </td></tr><tr><td> <code class="notranslate">--zero-superblock</code> </td><td> Löschen des RAID-Superblocks </td><td> 6 </td></tr></table><p>
</p></div></div></div><div class="section_1"><h2 id="Problembehebung">Problembehebung<a class="headerlink" href="#Problembehebung">¶</a></h2><p>
</p><div class="section_2"><h3 id="Bootprobleme">Bootprobleme<a class="headerlink" href="#Bootprobleme">¶</a></h3><p>
</p><pre class="notranslate">GRUB 2: unknown Filesystem</pre><p>
Falls das System nicht bootet, nachdem man es auf ein RAID 1 kopiert, die <strong>/etc/fstab</strong><sup><a href="#source-9">[9]</a></sup> angepasst, die <a class="internal" href="./grub_2/konfiguration.html#Standardeintraege-in-die-grub-cfg">grub.cfg</a> und die <a class="crosslink" href="#mdadm-conf-aktualisieren">mdadm.conf</a> korrekt erscheinen sowie das <a class="crosslink" href="#mdadm-conf-aktualisieren">initramfs</a> aktualisiert wurde, kann es helfen, GRUB 2 wie unter <a class="internal" href="./grub_2/reparatur.html#Root-Directory-Methode">GRUB 2/Reparatur</a> beschrieben erneut zu installieren. Dabei muss auf die Art der Partitionstabelle geachtet werden. Die obige Anleitung nutzt GPT-Partitionstabellen.</p></div><div class="section_2"><h3 id="RAID-startet-nicht">RAID startet nicht<a class="headerlink" href="#RAID-startet-nicht">¶</a></h3><p>
</p><pre class="notranslate">mdadm: Cannot open /dev/sdXY: Device or resource busy</pre><p>
Falls beim Erstellen eines RAIDs diese Meldung erscheint und mit den Partitionen bereits einmal ein RAID erstellt wurde, muss zunächst der alte Verbund <a class="crosslink" href="#RAID-aufloesen">aufgelöst</a> werden.</p></div><div class="section_2"><h3 id="Fehler-beim-Update-des-Kernels-nach-Festplattentausch">Fehler beim Update des Kernels nach Festplattentausch<a class="headerlink" href="#Fehler-beim-Update-des-Kernels-nach-Festplattentausch">¶</a></h3><p>
</p><pre class="notranslate">Grub-Konfigurationsdatei wird generiert …
grub-probe: Warnung: Physischer Datenträger »(null)« konnte nicht gefunden werden. Einige Module könnten im Core-Abbild fehlen..
/usr/sbin/grub-probe: Warnung: Physischer Datenträger »(null)« konnte nicht gefunden werden. Einige Module könnten im Core-Abbild fehlen..</pre><p>
Treten nach dem Tausch einer Festplatte diese Fehler auf muss die Device Map von Grub neu geschrieben werden. Dies geschieht mit:
</p><div class="bash"><div class="contents"><pre class="notranslate">sudo grub-mkdevicemap </pre></div></div><p>
Geht alles glatt, darf keine Ausgabe erscheinen. Anschließend noch einmal Grub aktualisieren:
</p><div class="bash"><div class="contents"><pre class="notranslate">sudo grub-update </pre></div></div><p>
Nun sollte der Fehler behoben sein und die Grubkonfiguration sich ohne Fehler aktualisieren.</p></div></div><div class="section_1"><h2 id="Komplexe-Aufgaben">Komplexe Aufgaben<a class="headerlink" href="#Komplexe-Aufgaben">¶</a></h2><p>
Dieser Abschnitt fasst komplexere Szenarien und Methoden zusammen, die im normalen Betrieb nicht auftreten, aber für Nutzer mit speziellen Anforderungen nützlich sein können.</p><div class="section_2"><h3 id="Resync-und-Rebuild-beschleunigen">Resync und Rebuild beschleunigen<a class="headerlink" href="#Resync-und-Rebuild-beschleunigen">¶</a></h3><p>
Wie eingangs erläutert ermöglicht ein RAID unterbrechungsfreien Zugriff auf die gespeicherten Daten auch während eines Ausfalls. Daten können also auch während eines Resyncs oder Rebuilds gelesen und geschrieben werden, wenn auch mit verringerter Geschwindigkeit. Lese- und Schreibzugriffe wirken sich umgekehrt wiederum auf die Geschwindigkeit von Resnyc- und Rebuild-Vorgängen aus. Die Balance zwischen Lese-/Schreib-Performance und Resync-/Rebuild-Geschwindigkeit kann über zwei (virtuelle) Dateien im <em>proc</em>-System gesteuert werden:</p><table><tr class="kopf"><td>Pfad </td><td> Standardwert (in KiB/s) </td><td> Bedeutung </td></tr><tr><td> <code class="notranslate">/proc/sys/dev/raid/speed_limit_min</code> </td><td> 1000 </td><td> Das System wird ggf. Lese- und Schreibzugriffen verlangsamen, falls die Resync-/Rebuild-Geschwindigkeit unter diesen Wert zu fallen droht.</td></tr><tr><td> <code class="notranslate">/proc/sys/dev/raid/speed_limit_max</code> </td><td> 200000 </td><td> Das System wird Rebuild und Resync höchstens mit dieser Geschwindigkeit durchführen und eventuellen Überschuss für Lese-/Schreib-Zugriffe frei halten.</td></tr></table><p>
Da der Standard-Maximalwert von knapp 200 MiB/s die Leistung normaler Festplatten (mit Ausnahme von SSDs) übersteigt, wird das System effektiv immer versuchen, Resync und Rebuild so schnell wie möglich zu beenden, falls keine Lese- oder Schreibzugriffe stattfinden. Falls sich Zugriffe nicht vermeiden lassen (zum Beispiel, wenn das root-Dateisystem auf dem RAID liegt) und Rebuild/Resync trotzdem Vorrang haben sollen, kann die Mindestgeschwindigkeit temporär auf einen praktisch nicht erreichbaren Wert angehoben werden:</p><div class="bash"><div class="contents"><pre class="notranslate">sudo su -c "echo 200000 &gt; /proc/sys/dev/raid/speed_limit_min" </pre></div></div><p>
Gerade im Fall des root-Dateisystems kann die damit einhergehende verringerte Lese- und Schreibgeschwindigkeit jedoch zu einem instabilem, effektiv nicht mehr nutzbaren System führen. Änderung an den Standardwerten sind daher mit Vorsicht zu genießen. Bei einem Neustart werden automatisch die Standardwerte wiederhergestellt. Um den Wert per Hand zurückzusetzen:</p><div class="bash"><div class="contents"><pre class="notranslate">sudo su -c "echo 1000 &gt; /proc/sys/dev/raid/speed_limit_min" </pre></div></div><p>In Einzelfällen kann das Aushängen des Dateisystems (falls möglich) den Vorgang beschleunigen. Im Regelfall wird dies jedoch keinen Vorteil bringen. In jedem Fall widerspricht dies natürlich dem Grundgedanken eines RAIDs, die Daten in jedem Fall verfügbar zu halten:</p><div class="bash"><div class="contents"><pre class="notranslate">sudo umount /dev/md0 </pre></div></div><p>Generell sollte man von diesen Möglichkeiten keine Wunder erwarten. Resync und Rebuild erfordern im Allgemeinen das komplette Lesen und Neubeschreiben aller beteiligten Laufwerke und können damit maximal so schnell durchgeführt werden, wie es das langsamste, am RAID beteiligte, Laufwerk erlaubt. Zeiten im Bereich von mehreren Tagen sind bei entsprechender Größe völlig normal.</p><p>Wenn man möchte, kann man während der Vorgänge mit <a class="internal" href="./watch.html">watch</a> den Fortschritt kontrollieren:
</p><div class="bash"><div class="contents"><pre class="notranslate">watch cat /proc/mdstat </pre></div></div><p>
Die Anzeige kann mit 
<span class="key">Strg</span>  + 
<span class="key">C</span>  beendet werden.</p></div><div class="section_2"><h3 id="Wechsel-des-Betriebssystems">Wechsel des Betriebssystems<a class="headerlink" href="#Wechsel-des-Betriebssystems">¶</a></h3><p>
Für den Fall, dass man das Betriebssystem neu aufsetzen muss oder ein zweites Betriebssystem auf dem Rechner installieren will, kann man das Software-RAID weiter verwenden – sofern das Betriebssystem nicht direkt auf dem Software-RAID angelegt ist. Dazu muss auf dem neuen System das Paket</p><ul><li><p><strong>mdadm</strong></p></li></ul><p><img alt="Wiki/Vorlagen/Installbutton/button.png" class="image-default" src="./_/fd60ccb86c4d96df2f4518df2936cc7d038467aa.png"/>
mit <a class="internal" href="./apturl.html">apturl</a>
</p><div class="package-list"><div class="contents"><p>
Paketliste zum Kopieren:
</p><div class="bash"><div class="contents"><pre class="notranslate">sudo apt-get install mdadm </pre></div></div><p>
</p><div class="bash"><div class="contents"><pre class="notranslate">sudo aptitude install mdadm </pre></div></div><p>
</p></div></div><p>
installiert<sup><a href="#source-2">[2]</a></sup> werden. Spätestens bei einem Neustart sollten bestehenden Arrays automatisch erkannt und gestartet werden. Falls dies nicht funktioniert, weil z.B. Arrays mit alten Superblock-Versionen vorhanden sind, kann man dies auch per Hand aktivieren:</p><div class="box warning"><h3 class="box warning">Achtung!</h3><div class="contents"><p>Auf keinen Fall darf man hier die Optionen "<code class="notranslate">--create</code>" verwenden, da sonst die Lesbarkeit auf den beteiligten Partitionen zerstört wird.
</p></div></div><p>Das RAID nutzbar machen:
</p><ul><li><p>RAID aus den gefundenen Superblöcken neu assemblieren:</p><div class="bash"><div class="contents"><pre class="notranslate">sudo mdadm --assemble --scan </pre></div></div><ul><li><p>Hat man mehrere Software-RAIDs und möchte ein bestimmtes RAID zusammenführen, kann man dies durch die Angabe der <a class="internal" href="./uuid.html">UUID</a> des entsprechenden RAIDs tun:</p><div class="bash"><div class="contents"><pre class="notranslate">sudo mdadm --assemble --scan --uuid=6c926c35:380d7ab2:3603cf0e:ecfa67b9 </pre></div></div></li><li><p>Durch die Angabe der einzelnen Partitionen:</p><div class="bash"><div class="contents"><pre class="notranslate">sudo mdadm --assemble /dev/md0 /dev/sde1 /dev/sdf1 /dev/sdg1 </pre></div></div></li></ul></li></ul><p>
Soll von dem neuen RAID-Verbund gebootet werden (Root-Dateisystem), dann muss noch der <a class="crosslink" href="#Bootloader">Bootloader installiert</a> und das <a class="crosslink" href="#mdadm-conf-aktualisieren">initramfs</a> aktualisiert werden.</p></div><div class="section_2"><h3 id="Live-System">Live System<a class="headerlink" href="#Live-System">¶</a></h3><p>
Um auf einen RAID-Verbund mittels einer <a class="internal" href="./live-cd.html">Live-CD</a> bzw. eines <a class="internal" href="./live-usb.html">Live-USB</a> zuzugreifen, muss das Programmpaket <strong>mdadm</strong> mit</p><div class="bash"><div class="contents"><pre class="notranslate">sudo apt-get install  --no-install-recommends mdadm </pre></div></div><p>
installiert werden. Die Option <code class="notranslate">--no-install-recommends</code> verhindert dabei die Installation des Mail-Server <a class="internal" href="./postfix.html">Postfix</a>. Anschließend werden mit:</p><div class="bash"><div class="contents"><pre class="notranslate">sudo mdadm --assemble --scan </pre></div></div><p>
alle gefundenen RAID-Verbunde aktiviert. Mit dem Befehl:</p><div class="bash"><div class="contents"><pre class="notranslate">cat /proc/mdstat </pre></div></div><p>
kann man dann wieder die gefundenen RAID-Verbunde anzeigen. Nun wird das RAID noch mit:</p><div class="bash"><div class="contents"><pre class="notranslate">mkdir /media/raid
mount /dev/md0 /media/raid </pre></div></div><p>
in den Verzeichnisbaum integriert. Jetzt kann man die Daten im Verzeichnis <strong>/media/raid</strong> lesen (bei Bedarf auch verändern), sowie auf eine externe Festplatte oder in ein Netzwerkverzeichnis kopieren.</p><p>Wenn man auf defekte/fehlende Festplatten zugreifen muss, dann schlägt ein <code class="notranslate">--assemble --scan</code> fehl und die Partitionen müssen einzeln assemblieren werden. Dazu wird z.B. <code class="notranslate">sda1</code> als Quelle angegeben (bei RAID 0 nicht möglich):</p><div class="bash"><div class="contents"><pre class="notranslate">sudo mdadm --assemble --run /dev/md0 /dev/sda1 </pre></div></div><p>
Dabei bewirkt das <code class="notranslate">--run</code>, dass der Verbund aktiviert wird. Nach dem Einhängen in den Verzeichnisbaum sollte man auf die Daten zugreifen können.</p><p>Weitere Möglichkeiten, z.B. bei der Reparatur des RAID, bieten die <a class="internal" href="./grub_2/reparatur.html#Root-Directory-Methode">Root-Directory-</a>, die <a class="internal" href="./grub_2/reparatur.html#chroot-Methode">Chroot-</a> oder die <a class="internal" href="./grub_2/terminalbefehle.html#grub-setup">Setup-</a>Methode.</p></div><div class="section_2"><h3 id="Kombinierte-RAIDs">Kombinierte RAIDs<a class="headerlink" href="#Kombinierte-RAIDs">¶</a></h3><p>
Wem die oben genannten Möglichkeiten nicht ausreichen, kann auch nach eigenen Anforderungen verschiedenen RAID-Arten kombinieren. So ist es zum Beispiele möglich, zwei RAID 5 zu spiegeln, also als RAID 1 zu betreiben:</p><ol class="arabic"><li><p>Aus <code class="notranslate">sde1</code>, <code class="notranslate">sdf1</code> und <code class="notranslate">sdg1</code> wird ein RAID 5 erstellt</p></li><li><p>Aus <code class="notranslate">sdh1</code>, <code class="notranslate">sdj1</code> und <code class="notranslate">sdk1</code> wird ebenfalls ein RAID 5 erstellt</p></li><li><p>Aus den beiden RAID 5 wird dann ein RAID 1 erstellt: </p><div class="bash"><div class="contents"><pre class="notranslate">sudo mdadm --create --verbose /dev/md0 --level=5 --raid-devices=3 /dev/sde1 /dev/sdf1 /def/sdg1
sudo mdadm --create --verbose /dev/md1 --level=5 --raid-devices=3 /dev/sdh1 /dev/sdj1 /dev/sdk1 
sudo mdadm --create --verbose /dev/md2 --level=1 --raid-devices=2 /dev/md0 /dev/md1  </pre></div></div></li></ol><p>Ein solcher Verbund würde als RAID 51 bezeichnet werden, also ein RAID 1 über mehrere RAID 5. Im Allgemeinen sind solche exotischen Kombinationen zwar selten sinnvoll (je komplexer, desto fehleranfälliger sind Wartung und Reparatur), aber prinzipiell sind beliebige Kombinationen möglich. Eine sinnvolle Kombination, ein RAID 0 über mehrere RAID 1, also ein RAID 10, wird direkt von mdadm als RAID-Level unterstützt und muss nicht wie hier beschrieben per Hand angelegt werden.</p><p>Alternativ verwendet man auch gerne mehrere RAIDs in Zusammenarbeit mit <a class="internal" href="./lvm.html">LVM</a>, da dieses einen sehr flexiblen Umgang mit RAID-Verbünden ermöglicht. Zudem sind dadurch auch sehr große Dateisysteme mit etlichen Terabytes und sogar Petabytes realisierbar.</p></div><div class="section_2"><h3 id="RAID-aufloesen">RAID auflösen<a class="headerlink" href="#RAID-aufloesen">¶</a></h3><p>
Um den Verbund eines RAID aufzulösen, d.h. die Ressourcen wieder freizugeben, geht man wie folgt vor:</p><ol class="arabic"><li><p>Stoppen des RAID-Verbundes: </p><div class="bash"><div class="contents"><pre class="notranslate">sudo umount /dev/md0
sudo mdadm --stop /dev/md0 </pre></div></div></li><li><p>In der <strong>/etc/fstab</strong> die aufgelösten RAIDs entfernen.</p></li><li><p>Mit einem Editor in der <a class="crosslink" href="#mdadm-conf-aktualisieren">mdadm.conf</a> die Array-Angaben löschen.</p></li><li><p>Den Superblock der entfernten Partitionen löschen, hier am Beispiel von <code class="notranslate">sde1</code> und <code class="notranslate">sdf1</code>:</p><div class="bash"><div class="contents"><pre class="notranslate">sudo mdadm --zero-superblock /dev/sde1 /dev/sdf1 </pre></div></div></li><li><p>Die Partitions-ID wieder auf normale Linux-ID ändern (bei MBR) beziehungsweise das RAID-Flag der Partition ausschalten (bei GPT).</p></li></ol><p>
Auf die vorhandenen Daten kann anschließend nicht mehr zugegriffen werden. Die Partitionen auf den Festplatten sind aber immernoch vorhanden, solange diese nicht überschrieben werden.</p></div><div class="section_2"><h3 id="Bootloader">Bootloader<a class="headerlink" href="#Bootloader">¶</a></h3><p>
Betreibt man einen RAID-Verbund als Systemlaufwerk, ist es praktisch, wenn das System auch noch nach Ausfall einer Festplatte hochfahren kann. Das wird z.B. bei ferngewarteten Rechnern benötigt, auf die man keinen direkten Zugriff hat. Da sich der Bootloader <a class="internal" href="./grub_2.html">GRUB 2</a> in der Standardkonfiguration nur auf einem der Laufwerke installiert, muss man etwas nachhelfen. Dazu installiert man den Bootloader auf allen dem RAID-Verbund angehörenden Laufwerken.</p><ul><li><p><strong>MPT</strong>: <a class="internal" href="./grub_2/installation.html">Installation</a> des Bootloaders in alle MBR aller beteiligten Festplatten (<code class="notranslate">grub-install /dev/sdX</code>), wobei die neu eingerichteten Festplatten anzugegeben sind. Am schnellsten geht es mit dem Befehl: </p><div class="bash"><div class="contents"><pre class="notranslate">sudo dpkg-reconfigure grub-pc </pre></div></div><p> und der anschließenden Auswahl der gewünschten Festplatten.</p></li><li><p><strong>GPT</strong>: Der Bootloader muss in die entsprechenden <a class="internal" href="./grub_2/grundlagen.html#MBR-mit-GUID-Partitionstabelle-GPT">Boot-Partitionen</a> installiert werden. Bei z.B. einer Installation mit GPT &amp; BIOS bricht die Installation von <a class="internal" href="./grub_2/problembehebung.html#Probleme-bei-der-Installation">GRUB 2</a> sonst ab und weist mit einer Fehlermeldung auf die fehlende Partition hin.</p><pre class="notranslate">grub-installer: /usr/sbin/grub-setup: warn: This GPT partition label has no BIOS Boot Partition; embedding won't be possible!</pre></li></ul><p>
Damit die Boot-Partitionen durch die <code class="notranslate">initrd</code> auch einwandfrei gemountet werden, sollte nach Änderung die <a class="crosslink" href="#mdadm-conf-aktualisieren">mdadm.conf und initrd aktualisiert</a> werden.</p></div><div class="section_2"><h3 id="USB-und-RAID">USB und RAID<a class="headerlink" href="#USB-und-RAID">¶</a></h3><p>
RAID 0 (stripping) ist denkbar ungeeignet für ein USB-RAID, da bei diesem das Entfernen einer Platte direkt zum Defekt des RAID-Verbunds führt. Mit RAID 5 und 6 kann es kritisch werden, es sollte aber funktionieren, auch wenn davon stark abzuraten ist. RAID 1 (mirror) mit mehreren Partitionen auf verschiedenen USB-Festplatten ist prinzipiell kein Problem, auch wenn davon im Allgemeinen abzuraten ist (siehe <a class="crosslink" href="#RAID-und-Backup">RAID und Backup</a>). Wer trotzdem sicher ist, dass in Spezialfällen ein RAID mit USB-Geräten sinnvoll ist, sollte noch folgendes beachten:</p><ul><li><p>Bei USB-Festplatten muss man unterbinden, dass ein Benutzer versucht, diese einzuhängen bzw. dass das System dies am Anfang nicht selbst probiert. Da alle am RAID beteiligten Partitionen die gleiche UUID haben sollten, kann man die <strong>/etc/fstab</strong> auf diese abstellen und um die Parameter <code class="notranslate">nouser</code> und <code class="notranslate">noauto</code> erweitern.</p></li></ul><p>
</p></div><div class="section_2"><h3 id="Raid-1-zu-Raid-0-konvertieren">Raid 1 zu Raid 0 konvertieren<a class="headerlink" href="#Raid-1-zu-Raid-0-konvertieren">¶</a></h3><p>
Ausgangssituation:</p><p>/dev/md0 ist ein Raid 1 aus /dev/sda1 und /dev/sdb1</p><p>Ziel:</p><p>/dev/md0 ist ein Raid 0 aus beiden Partitionen</p><div class="bash"><div class="contents"><pre class="notranslate">mdadm --grow /dev/md0 -l 0 </pre></div></div><p>
</p><pre class="notranslate">mdadm: level of /dev/md0 changed to raid0</pre><p>/dev/sda1 wurde aus dem Raid 1 entfernt</p><div class="bash"><div class="contents"><pre class="notranslate">mdadm --zero-superblock /dev/sda1
mdadm --grow /dev/md0 --level=4 --raid-devices=2 --add /dev/sda1 --backup-file=/root/raid.bak </pre></div></div><p>
</p><pre class="notranslate">mdadm: level of /dev/md0 changed to raid4
mdadm: added /dev/sda1
mdadm: Need to backup 128K of critical section..
mdadm: /dev/md0: could not set level to raid0</pre><p>/dev/md0 ist jetzt ein Raid 4 das gesynced wird. Raid 4 ist hier ein notwendiger Zwischenschritt. Synchronisation abwarten...</p><p>Dann Raid 4 zu Raid 0 konvertieren
</p><div class="bash"><div class="contents"><pre class="notranslate">mdadm --grow /dev/md0 --level=0 --raid-devices=2 --backup-file=/root/raid.bak </pre></div></div><p>Wieder das Reshaping abwarten...
</p><div class="bash"><div class="contents"><pre class="notranslate">watch mdadm -D /dev/md0 </pre></div></div><p>Fertig ist das Raid 0.</p></div></div><div class="section_1"><h2 id="Links">Links<a class="headerlink" href="#Links">¶</a></h2><p>
</p><ul><li><p>Manpages zu <a class="interwiki interwiki-man" href="http://manpages.ubuntu.com/cgi-bin/search.py?lr=lang_en&amp;q=mdadm">mdadm</a> <img alt="{en}" src="./_/d5ecf89114b079f85d02099649c4ee617ffa34c7.png"/> und <a class="interwiki interwiki-man" href="http://manpages.ubuntu.com/cgi-bin/search.py?lr=lang_en&amp;q=mdadm.conf">mdadm.conf</a> <img alt="{en}" src="./_/d5ecf89114b079f85d02099649c4ee617ffa34c7.png"/></p></li><li><p><a class="external" href="https://raid.wiki.kernel.org" rel="nofollow">Linux Raid</a> <img alt="{en}" src="./_/d5ecf89114b079f85d02099649c4ee617ffa34c7.png"/> - Dokumentation im Wiki von Kernel.org</p></li><li><p><a class="external" href="https://ctaas.de/software-raid.htm" rel="nofollow">ausführliches Howto</a> <img alt="{de}" src="./_/ffd333e1d59794eac31aea8b3e984e1b88473c33.png"/>  Dokumentation zum Einrichten und warten von einem Software-RAID</p></li><li><p><a class="external" href="http://www.linuxhomenetworking.com/wiki/index.php/Quick_HOWTO_:_Ch26_:_Linux_Software_RAID" rel="nofollow">Quick HOWTO - Linux Software RAID</a> </p></li><li><p><a class="external" href="http://busybox.net/~aldot/mkfs_stride.html" rel="nofollow">RAID Stride Calculator</a> <img alt="{en}" src="./_/d5ecf89114b079f85d02099649c4ee617ffa34c7.png"/> - Webseite zur Berechnung der Stride-Parameter</p></li></ul><p>
</p></div></div>
<p class="meta">
<a href="./software-raid/a/revision/943928.html">Diese Revision</a> wurde am 1. Oktober 2017 21:24 von <a href="https://ubuntuusers.de/user/superhonk/">superhonk</a> erstellt.
    
  </p>
</div>
</div>
<div style="clear: both;"></div>
<div class="pathbar breadcrumb">
<div class="breadcrumb">
<ol>
<li><a href="./startseite.html">Wiki</a></li>
<li><a href="./software-raid.html">Software-RAID</a></li>
</ol>
</div>
</div>
</div>
<div class="footer" style="clear: both;">
<ul>
<li class="poweredby"><li class="poweredby">Erstellt mit <a href="http://inyokaproject.org/">Inyoka</a></li></li>
<li class="license">

<img alt="Copyleft" src="./_/65dad5b770326dbbe1bd26ee6363e366a76bd8b7.png"/>
          2004 – 2017 ubuntuusers.de • Einige Rechte vorbehalten<br/>
<a href="./_lizenz.html" rel="cc:morePermissions">Lizenz</a> •
          <a href="http://ubuntuusers.de/kontakt/">Kontakt</a> •
          <a href="http://ubuntuusers.de/datenschutz/">Datenschutz</a> •
          <a href="http://ubuntuusers.de/impressum/">Impressum</a> •
          <a href="https://ubuntuusers.statuspage.io">Serverstatus</a>
</li>
<li class="housing">
<span title="Unterbringung und Netzanbindung eines Servers">Serverhousing</span> gespendet von<br/>
<img alt="noris network" src="./_/e7d27e9081eec23a8a5a5fe9434d7b2f1532e1d9.png"/>
<img alt="anexia" src="./_/ad1b63a3fc35749344af0a03e8c3ce05a2a3ee7e.png"/>
</li>
</ul>
</div>
<div style="clear: both;"></div>
</div>






</body>
</html>